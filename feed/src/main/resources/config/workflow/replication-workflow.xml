<!--
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
  -->
<workflow-app xmlns='uri:oozie:workflow:0.3' name='falcon-feed-parent-workflow'>
    <start to='should-record'/>
    <decision name='should-record'>
        <switch>
            <case to="recordsize">
                ${shouldRecord=="true"}
            </case>
            <default to="replication-decision"/>
        </switch>
    </decision>
    <action name='recordsize'>
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>oozie.launcher.mapred.job.priority</name>
                    <value>${jobPriority}</value>
                </property>
                <!-- HCatalog jars -->
                <property>
                    <name>oozie.use.system.libpath</name>
                    <value>true</value>
                </property>
                <property>
                    <name>oozie.action.sharelib.for.java</name>
                    <value>hcatalog</value>
                </property>
            </configuration>
            <main-class>org.apache.falcon.latedata.LateDataHandler</main-class>
            <arg>-out</arg>
            <arg>${logDir}/latedata/${nominalTime}/${srcClusterName}</arg>
            <arg>-paths</arg>
            <arg>${falconInPaths}</arg>
            <arg>-falconInputFeeds</arg>
            <arg>${falconInputFeeds}</arg>
            <arg>-falconInputFeedStorageTypes</arg>
            <arg>${falconInputFeedStorageTypes}</arg>
            <capture-output/>
        </java>
        <ok to="replication-decision"/>
        <error to="failed-post-processing"/>
    </action>
    <decision name="replication-decision">
        <switch>
            <case to="table-export">
                ${falconFeedStorageType == "TABLE"}
            </case>
            <default to="replication"/>
        </switch>
    </decision>
    <!-- Table Replication - Export data and metadata to HDFS Staging from Source Hive -->
    <action name="table-export">
        <hive xmlns="uri:oozie:hive-action:0.2">
            <job-tracker>${falconSourceJobTracker}</job-tracker>
            <name-node>${falconSourceNameNode}</name-node>
            <prepare>
                <delete path="${distcpSourcePaths}"/>
            </prepare>
            <job-xml>${wf:appPath()}/conf/falcon-source-hive-site.xml</job-xml>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>oozie.launcher.mapred.job.priority</name>
                    <value>${jobPriority}</value>
                </property>
            </configuration>
            <script>${wf:appPath()}/scripts/falcon-table-export.hql</script>
            <param>falconSourceDatabase=${falconSourceDatabase}</param>
            <param>falconSourceTable=${falconSourceTable}</param>
            <param>falconSourcePartition=${falconSourcePartition}</param>
            <param>falconSourceStagingDir=${distcpSourcePaths}</param>
        </hive>
        <ok to="replication"/>
        <error to="failed-post-processing"/>
    </action>
    <!-- Replication action -->
    <action name="replication">
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>oozie.launcher.mapred.job.priority</name>
                    <value>${jobPriority}</value>
                </property>
            </configuration>
            <main-class>org.apache.falcon.replication.FeedReplicator</main-class>
            <arg>-Dfalcon.include.path=${sourceRelativePaths}</arg>
            <arg>-Dmapred.job.queue.name=${queueName}</arg>
            <arg>-Dmapred.job.priority=${jobPriority}</arg>
            <arg>-maxMaps</arg>
            <arg>${maxMaps}</arg>
            <arg>-sourcePaths</arg>
            <arg>${distcpSourcePaths}</arg>
            <arg>-targetPath</arg>
            <arg>${distcpTargetPaths}</arg>
            <arg>-falconFeedStorageType</arg>
            <arg>${falconFeedStorageType}</arg>
            <file>${wf:conf("falcon.libpath")}/hadoop-distcp.jar</file>
        </java>
        <ok to="post-replication-decision"/>
        <error to="failed-post-processing"/>
    </action>
    <decision name="post-replication-decision">
        <switch>
            <case to="table-import">
                ${falconFeedStorageType == "TABLE"}
            </case>
            <default to="succeeded-post-processing"/>
        </switch>
    </decision>
    <!-- Table Replication - Import data and metadata from HDFS Staging into Target Hive -->
    <action name="table-import">
        <hive xmlns="uri:oozie:hive-action:0.2">
            <job-tracker>${falconTargetJobTracker}</job-tracker>
            <name-node>${falconTargetNameNode}</name-node>
            <job-xml>${wf:appPath()}/conf/falcon-target-hive-site.xml</job-xml>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>oozie.launcher.mapred.job.priority</name>
                    <value>${jobPriority}</value>
                </property>
            </configuration>
            <script>${wf:appPath()}/scripts/falcon-table-import.hql</script>
            <param>falconTargetDatabase=${falconTargetDatabase}</param>
            <param>falconTargetTable=${falconTargetTable}</param>
            <param>falconTargetPartition=${falconTargetPartition}</param>
            <param>falconTargetStagingDir=${distcpTargetPaths}</param>
        </hive>
        <ok to="succeeded-post-processing"/>
        <error to="failed-post-processing"/>
    </action>
    <action name='succeeded-post-processing'>
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>oozie.launcher.mapred.job.priority</name>
                    <value>${jobPriority}</value>
                </property>
            </configuration>
            <main-class>org.apache.falcon.workflow.FalconPostProcessing</main-class>
            <arg>-cluster</arg>
            <arg>${cluster}</arg>
            <arg>-entityType</arg>
            <arg>${entityType}</arg>
            <arg>-entityName</arg>
            <arg>${entityName}</arg>
            <arg>-nominalTime</arg>
            <arg>${nominalTime}</arg>
            <arg>-operation</arg>
            <arg>REPLICATE</arg>
            <arg>-workflowId</arg>
            <arg>${wf:id()}</arg>
            <arg>-runId</arg>
            <arg>${wf:run()}</arg>
            <arg>-status</arg>
            <arg>SUCCEEDED</arg>
            <arg>-timeStamp</arg>
            <arg>${timeStamp}</arg>
            <arg>-brokerImplClass</arg>
            <arg>${wf:conf("broker.impl.class")}</arg>
            <arg>-brokerUrl</arg>
            <arg>${wf:conf("broker.url")}</arg>
            <arg>-userBrokerImplClass</arg>
            <arg>${userBrokerImplClass}</arg>
            <arg>-userBrokerUrl</arg>
            <arg>${userBrokerUrl}</arg>
            <arg>-brokerTTL</arg>
            <arg>${wf:conf("broker.ttlInMins")}</arg>
            <arg>-feedNames</arg>
            <arg>${feedNames}</arg>
            <arg>-feedInstancePaths</arg>
            <arg>${feedInstancePaths}</arg>
            <arg>-logFile</arg>
            <arg>${logDir}/instancePaths-${nominalTime}-${srcClusterName}.csv</arg>
            <arg>-workflowEngineUrl</arg>
            <arg>${workflowEngineUrl}</arg>
            <arg>-userWorkflowName</arg>
            <arg>${userWorkflowName}</arg>
            <arg>-userWorkflowVersion</arg>
            <arg>${userWorkflowVersion}</arg>
            <arg>-userWorkflowEngine</arg>
            <arg>${userWorkflowEngine}</arg>
            <arg>-subflowId</arg>
            <arg>${wf:id()}</arg>
            <arg>-logDir</arg>
            <arg>${logDir}/job-${nominalTime}/${srcClusterName}/</arg>
            <arg>-workflowUser</arg>
            <arg>${wf:user()}</arg>
            <arg>-falconInputFeeds</arg>
            <arg>${falconInputFeeds}</arg>
            <arg>-falconInputPaths</arg>
            <arg>${falconInPaths}</arg>
            <file>${wf:conf("falcon.libpath")}/activemq-core.jar</file>
            <file>${wf:conf("falcon.libpath")}/geronimo-j2ee-management.jar</file>
            <file>${wf:conf("falcon.libpath")}/jms.jar</file>
            <file>${wf:conf("falcon.libpath")}/json-simple.jar</file>
            <file>${wf:conf("falcon.libpath")}/oozie-client.jar</file>
            <file>${wf:conf("falcon.libpath")}/spring-jms.jar</file>
        </java>
        <ok to="end"/>
        <error to="fail"/>
    </action>
    <action name='failed-post-processing'>
        <java>
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <configuration>
                <property>
                    <name>mapred.job.queue.name</name>
                    <value>${queueName}</value>
                </property>
                <property>
                    <name>oozie.launcher.mapred.job.priority</name>
                    <value>${jobPriority}</value>
                </property>
            </configuration>
            <main-class>org.apache.falcon.workflow.FalconPostProcessing</main-class>
            <arg>-cluster</arg>
            <arg>${cluster}</arg>
            <arg>-entityType</arg>
            <arg>${entityType}</arg>
            <arg>-entityName</arg>
            <arg>${entityName}</arg>
            <arg>-nominalTime</arg>
            <arg>${nominalTime}</arg>
            <arg>-operation</arg>
            <arg>REPLICATE</arg>
            <arg>-workflowId</arg>
            <arg>${wf:id()}</arg>
            <arg>-runId</arg>
            <arg>${wf:run()}</arg>
            <arg>-status</arg>
            <arg>FAILED</arg>
            <arg>-timeStamp</arg>
            <arg>${timeStamp}</arg>
            <arg>-brokerImplClass</arg>
            <arg>${wf:conf("broker.impl.class")}</arg>
            <arg>-brokerUrl</arg>
            <arg>${wf:conf("broker.url")}</arg>
            <arg>-userBrokerImplClass</arg>
            <arg>${userBrokerImplClass}</arg>
            <arg>-userBrokerUrl</arg>
            <arg>${userBrokerUrl}</arg>
            <arg>-brokerTTL</arg>
            <arg>${wf:conf("broker.ttlInMins")}</arg>
            <arg>-feedNames</arg>
            <arg>${feedNames}</arg>
            <arg>-feedInstancePaths</arg>
            <arg>${feedInstancePaths}</arg>
            <arg>-logFile</arg>
            <arg>${logDir}/instancePaths-${nominalTime}-${srcClusterName}.csv</arg>
            <arg>-workflowEngineUrl</arg>
            <arg>${workflowEngineUrl}</arg>
            <arg>-subflowId</arg>
            <arg>${wf:id()}</arg>
            <arg>-logDir</arg>
            <arg>${logDir}/job-${nominalTime}/${srcClusterName}/</arg>
            <arg>-workflowUser</arg>
            <arg>${wf:user()}</arg>
            <file>${wf:conf("falcon.libpath")}/activemq-core.jar</file>
            <file>${wf:conf("falcon.libpath")}/geronimo-j2ee-management.jar</file>
            <file>${wf:conf("falcon.libpath")}/jms.jar</file>
            <file>${wf:conf("falcon.libpath")}/json-simple.jar</file>
            <file>${wf:conf("falcon.libpath")}/oozie-client.jar</file>
            <file>${wf:conf("falcon.libpath")}/spring-jms.jar</file>
        </java>
        <ok to="fail"/>
        <error to="fail"/>
    </action>
    <kill name="fail">
        <message>
            Workflow failed, error message[${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>
    <end name='end'/>
</workflow-app>
