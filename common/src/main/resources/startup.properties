#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

*.domain=debug

######### Implementation classes #########
## DONT MODIFY UNLESS SURE ABOUT CHANGE ##

*.workflow.engine.impl=org.apache.falcon.workflow.engine.OozieWorkflowEngine
*.lifecycle.engine.impl=org.apache.falcon.lifecycle.engine.oozie.OoziePolicyBuilderFactory
*.oozie.process.workflow.builder=org.apache.falcon.workflow.OozieProcessWorkflowBuilder
*.oozie.feed.workflow.builder=org.apache.falcon.workflow.OozieFeedWorkflowBuilder
*.SchedulableEntityManager.impl=org.apache.falcon.resource.SchedulableEntityManager
*.ConfigSyncService.impl=org.apache.falcon.resource.ConfigSyncService
*.ProcessInstanceManager.impl=org.apache.falcon.resource.InstanceManager
*.catalog.service.impl=org.apache.falcon.catalog.HiveCatalogService

##### Falcon Services #####
*.application.services=org.apache.falcon.security.AuthenticationInitializationService,\
                        org.apache.falcon.workflow.WorkflowJobEndNotificationService, \
                        org.apache.falcon.service.ProcessSubscriberService,\
                        org.apache.falcon.extensions.ExtensionService,\
                        org.apache.falcon.service.FeedSLAMonitoringService,\
                        org.apache.falcon.service.LifecyclePolicyMap,\
                        org.apache.falcon.entity.store.ConfigurationStore,\
                        org.apache.falcon.rerun.service.RetryService,\
                        org.apache.falcon.rerun.service.LateRunService,\
                        org.apache.falcon.metadata.MetadataMappingService,\
                        org.apache.falcon.service.LogCleanupService,\
                        org.apache.falcon.service.GroupsService,\
                        org.apache.falcon.service.ProxyUserService,\
                        org.apache.falcon.service.FalconJPAService
##Add if you want to send data to graphite
#                        org.apache.falcon.metrics.MetricNotificationService\
## Add if you want to use Falcon Azure integration ##
#                        org.apache.falcon.adfservice.ADFProviderService
## If you wish to use Falcon native scheduler add the commented out services below to application.services ##
#                        org.apache.falcon.notification.service.impl.JobCompletionService,\
#                        org.apache.falcon.notification.service.impl.SchedulerService,\
#                        org.apache.falcon.notification.service.impl.AlarmService,\
#                        org.apache.falcon.notification.service.impl.DataAvailabilityService,\
#                        org.apache.falcon.execution.FalconExecutionService,\



# List of Lifecycle policies configured.
*.falcon.feed.lifecycle.policies=org.apache.falcon.lifecycle.retention.AgeBasedDelete
# List of builders for the policies.
*.falcon.feed.lifecycle.policy.builders=org.apache.falcon.lifecycle.engine.oozie.retention.AgeBasedDeleteBuilder
##### Falcon Configuration Store Change listeners #####
*.configstore.listeners=org.apache.falcon.entity.v0.EntityGraph,\
                        org.apache.falcon.entity.ColoClusterRelation,\
                        org.apache.falcon.group.FeedGroupMap,\
                        org.apache.falcon.entity.store.FeedLocationStore,\
                        org.apache.falcon.service.FeedSLAMonitoringService,\
                        org.apache.falcon.service.SharedLibraryHostingService
## If you wish to use Falcon native scheduler, add the State store as a configstore listener. ##
#                       org.apache.falcon.state.store.jdbc.JdbcStateStore

## If you wish to use Feed Alert to know when a feed misses a high SLA register your class here
*.feedAlert.listeners=

##### JMS MQ Broker Implementation class #####
*.broker.impl.class=org.apache.activemq.ActiveMQConnectionFactory

##### List of shared libraries for Falcon workflows #####
*.shared.libs=activemq-all,geronimo-j2ee-management,jms,json-simple,oozie-client,spring-jms,commons-lang3,commons-el

##### Workflow Job Execution Completion listeners #####
*.workflow.execution.listeners=

######### Implementation classes #########


######### System startup parameters #########

# Location of libraries that is shipped to Hadoop
*.system.lib.location=${FALCON_HOME}/sharedlibs

# Location to store user entity configurations

#Configurations used in UTs
debug.config.store.uri=file://${user.dir}/target/store
#Location to store state of Feed SLA monitoring service
debug.feed.sla.service.store.uri= file://${user.dir}/target/data/sla/pendingfeedinstances
debug.config.oozie.conf.uri=${user.dir}/target/oozie
debug.system.lib.location=${system.lib.location}
debug.broker.url=vm://localhost
debug.retry.recorder.path=${user.dir}/target/retry
debug.libext.feed.retention.paths=${falcon.libext}
debug.libext.feed.replication.paths=${falcon.libext}
debug.libext.process.paths=${falcon.libext}

debug.extension.store.uri=file://${user.dir}/target/extension/store

#Configurations used in ITs
it.config.store.uri=file://${user.dir}/target/store
it.config.oozie.conf.uri=${user.dir}/target/oozie
it.system.lib.location=${system.lib.location}
it.broker.url=tcp://localhost:61616
it.retry.recorder.path=${user.dir}/target/retry
it.libext.feed.retention.paths=${falcon.libext}
it.libext.feed.replication.paths=${falcon.libext}
it.libext.process.paths=${falcon.libext}
it.workflow.execution.listeners=org.apache.falcon.catalog.CatalogPartitionHandler

*.falcon.cleanup.service.frequency=minutes(5)

######### Properties for Feed SLA Monitoring #########
# frequency of serialization for the state of FeedSLAMonitoringService - 1 hour
*.feed.sla.serialization.frequency.millis=3600000

# Maximum number of pending instances per feed that will be recorded. After this older instances will be removed in
# a FIFO fashion.
*.feed.sla.queue.size=288

# Do not change unless really sure
# Frequency in seconds of "status check" for pending feed instances, default is 10 mins = 10 * 60
*.feed.sla.statusCheck.frequency.seconds=600

# Do not change unless really sure
# Time Duration (in milliseconds) in future for generating pending feed instances.
# In every cycle pending feed instances are added for monitoring, till this time in future.
# It must be more than statusCheck frequency, default is 15 mins = 15 * 60 * 1000
*.feed.sla.lookAheadWindow.millis=900000


######### Properties for configuring JMS provider - activemq #########
# Default Active MQ url
*.broker.url=tcp://localhost:61616

# default time-to-live for a JMS message 3 days (time in minutes)
*.broker.ttlInMins=4320
*.entity.topic=FALCON.ENTITY.TOPIC
*.max.retry.failure.count=1
*.retry.recorder.path=${user.dir}/logs/retry

######### Properties for configuring iMon client and metric #########
*.internal.queue.size=1000


######### Graph Database Properties #########
# Graph implementation
*.falcon.graph.blueprints.graph=com.thinkaurelius.titan.core.TitanFactory

# Graph Storage
# IMPORTANT:   Please enable one of the graph db backend: hbase or berkeleydb, per instructions below.

# Enable the following for Berkeley DB.  Make sure je-5.0.73.jar is downloaded and available
# under Falcon webapp directory or under falcon server classpath.
#*.falcon.graph.storage.backend=berkeleyje
#*.falcon.graph.storage.directory=/${falcon.home}/data/graphdb
#*.falcon.graph.serialize.path=${user.dir}/target/graphdb

# Enable the following for HBase
#*.falcon.graph.storage.backend=hbase
# For standalone mode , set hostname to localhost; for distributed mode, set to the zookeeper quorum
# @see http://s3.thinkaurelius.com/docs/titan/current/hbase.html#_remote_server_mode_2
#*.falcon.graph.storage.hostname=localhost
#*.falcon.graph.storage.hbase.table=falcon_titan

# Avoid acquiring read lock when iterating over large graphs
# See http://s3.thinkaurelius.com/docs/titan/0.5.4/bdb.html
*.falcon.graph.storage.transactions=false

# Uncomment and override the following properties for enabling metrics for titan db and pushing them to graphite. You
# can use other reporters like ganglia also.
# Refer (http://thinkaurelius.github.io/titan/wikidoc/0.4.2/Titan-Performance-and-Monitoring)for finding the
# relevant configurations for your use case. NOTE: you have to prefix all the properties with "*.falcon.graph."
# *.falcon.graph.storage.enable-basic-metrics = true
# Required; IP or hostname string
# *.falcon.graph.metrics.graphite.hostname = 192.168.0.1
# Required; specify logging interval in milliseconds
# *.falcon.graph.metrics.graphite.interval = 60000

######### Authentication Properties #########

# Authentication type must be specified: simple|kerberos
*.falcon.authentication.type=simple

##### Service Configuration

# Indicates the Kerberos principal to be used in Falcon Service.
*.falcon.service.authentication.kerberos.principal=

# Location of the keytab file with the credentials for the Service principal.
*.falcon.service.authentication.kerberos.keytab=

# name node principal to talk to config store
*.dfs.namenode.kerberos.principal=

##### SPNEGO Configuration

# Authentication type must be specified: simple|kerberos|<class>
# org.apache.falcon.security.RemoteUserInHeaderBasedAuthenticationHandler can be used for backwards compatibility
*.falcon.http.authentication.type=simple

# Indicates how long (in seconds) an authentication token is valid before it has to be renewed.
*.falcon.http.authentication.token.validity=36000

# The signature secret for signing the authentication tokens.
*.falcon.http.authentication.signature.secret=falcon

# The domain to use for the HTTP cookie that stores the authentication token.
*.falcon.http.authentication.cookie.domain=

# Indicates if anonymous requests are allowed when using 'simple' authentication.
*.falcon.http.authentication.simple.anonymous.allowed=false

# Indicates the Kerberos principal to be used for HTTP endpoint.
# The principal MUST start with 'HTTP/' as per Kerberos HTTP SPNEGO specification.
*.falcon.http.authentication.kerberos.principal=

# Location of the keytab file with the credentials for the HTTP principal.
*.falcon.http.authentication.kerberos.keytab=

# The kerberos names rules is to resolve kerberos principal names, refer to Hadoop's KerberosName for more details.
*.falcon.http.authentication.kerberos.name.rules=DEFAULT

# Comma separated list of black listed users
*.falcon.http.authentication.blacklisted.users=

######### Authentication Properties #########


######### Authorization Properties #########

# Authorization Enabled flag: false (default)|true
*.falcon.security.authorization.enabled=false

# The name of the group of super-users
*.falcon.security.authorization.superusergroup=falcon

# Admin Users, comma separated users
*.falcon.security.authorization.admin.users=falcon,ambari-qa

# Admin Group Membership, comma separated users
*.falcon.security.authorization.admin.groups=falcon,staff

# Authorization Provider Implementation Fully Qualified Class Name
*.falcon.security.authorization.provider=org.apache.falcon.security.DefaultAuthorizationProvider

######### Authorization Properties #########

######### ADF Configurations start #########

# A String object that represents the namespace
*.microsoft.windowsazure.services.servicebus.namespace=

# Request and status queues on the namespace
*.microsoft.windowsazure.services.servicebus.requestqueuename=
*.microsoft.windowsazure.services.servicebus.statusqueuename=

# A String object that contains the SAS key name
*.microsoft.windowsazure.services.servicebus.sasKeyName=

# A String object that contains the SAS key
*.microsoft.windowsazure.services.servicebus.sasKey=

# A String object containing the base URI that is added to your Service Bus namespace to form the URI to connect
# to the Service Bus service. To access the default public Azure service, pass ".servicebus.windows.net"
*.microsoft.windowsazure.services.servicebus.serviceBusRootUri=

# Service bus polling frequency
*.microsoft.windowsazure.services.servicebus.polling.frequency=

# Super user
*.microsoft.windowsazure.services.servicebus.superuser=

######### ADF Configurations end ###########

######### SMTP Properties ########

# Setting SMTP hostname
#*.falcon.email.smtp.host=localhost

# Setting SMTP port number
#*.falcon.email.smtp.port=25

# Setting email from address
#*.falcon.email.from.address=falcon@localhost

# Setting email Auth
#*.falcon.email.smtp.auth=false

#Setting user name
#*.falcon.email.smtp.user=""

#Setting password
#*.falcon.email.smtp.password=""

# Setting monitoring plugin, if SMTP parameters is defined
#*.monitoring.plugins=org.apache.falcon.plugin.DefaultMonitoringPlugin,\
#                     org.apache.falcon.plugin.EmailNotificationPlugin

######### StateStore Properties #####
#*.falcon.state.store.impl=org.apache.falcon.state.store.jdbc.JDBCStateStore
#*.falcon.statestore.jdbc.driver=org.apache.derby.jdbc.EmbeddedDriver
#*.falcon.statestore.jdbc.url=jdbc:derby:data/statestore.db;create=true
#*.falcon.statestore.jdbc.username=sa
#*.falcon.statestore.jdbc.password=
#*.falcon.statestore.connection.data.source=org.apache.commons.dbcp.BasicDataSource
## Maximum number of active connections that can be allocated from this pool at the same time.
#*.falcon.statestore.pool.max.active.conn=10
#*.falcon.statestore.connection.properties=
## Indicates the interval (in milliseconds) between eviction runs.
#*.falcon.statestore.validate.db.connection.eviction.interval=300000
## The number of objects to examine during each run of the idle object evictor thread.
#*.falcon.statestore.validate.db.connection.eviction.num=10
## Creates Falcon DB.
## If set to true, it creates the DB schema if it does not exist. If the DB schema exists is a NOP.
## If set to false, it does not create the DB schema. If the DB schema does not exist it fails start up.
#*.falcon.statestore.create.db.schema=true

# Graphite properties
#*.falcon.graphite.hostname=localhost
#*.falcon.graphite.port=2003
#*.falcon.graphite.frequency=1
#*.falcon.graphite.prefix=falcon
