#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

##### NOTE: This is a TEMPLATE file which can be copied and edited

##### Recipe properties
falcon.recipe.name=hive-disaster-recovery


##### Workflow properties
falcon.recipe.workflow.name=hive-dr-workflow
# Provide Wf absolute path. This can be HDFS or local FS path. If WF is on local FS it will be copied to HDFS
falcon.recipe.workflow.path=/recipes/hive-replication/hive-disaster-recovery-secure-workflow.xml

##### Cluster properties

# Change the cluster name where replication job should run here
falcon.recipe.cluster.name=backupCluster
# Change the cluster hdfs write end point here. This is mandatory.
falcon.recipe.cluster.hdfs.writeEndPoint=hdfs://localhost:8020
# Change the cluster validity start time here
falcon.recipe.cluster.validity.start=2014-10-01T00:00Z
# Change the cluster validity end time here
falcon.recipe.cluster.validity.end=2016-12-30T00:00Z
# Change the cluster namenode kerberos principal. This is mandatory on secure clusters.
falcon.recipe.nn.principal=nn/_HOST@EXAMPLE.COM

##### Scheduling properties

# Change the process frequency here. Valid frequency type are minutes, hours, days, months
falcon.recipe.process.frequency=minutes(60)

##### Retry policy properties

falcon.recipe.retry.policy=periodic
falcon.recipe.retry.delay=minutes(30)
falcon.recipe.retry.attempts=3
falcon.recipe.retry.onTimeout=false

##### Tag properties - An optional list of comma separated tags, Key Value Pairs, separated by comma
##### Uncomment to add tags
#falcon.recipe.tags=owner=landing,pipeline=adtech

##### ACL properties - Uncomment and change ACL if authorization is enabled

#falcon.recipe.acl.owner=testuser
#falcon.recipe.acl.group=group
#falcon.recipe.acl.permission=0x755

##### Custom Job properties

##### Source Cluster DR properties
sourceCluster=primaryCluster
sourceMetastoreUri=thrift://localhost:9083
sourceHiveServer2Uri=hive2://localhost:10000
# For DB level replicaiton to replicate multiple databases specify comma separated list of tables
sourceDatabase=default
# For DB level replication specify * for sourceTable.
# For table level replication to replicate multiple tables specify comma separated list of tables
sourceTable=testtable_dr
## Please specify staging dir in the source without fully qualified domain name.
sourceStagingPath=/apps/hive/tools/dr
sourceNN=hdfs://localhost:8020
# Specify kerberos principal required to access source namenode and hive servers, optional on non-secure cluster.
sourceNNKerberosPrincipal=nn/_HOST@EXAMPLE.COM
sourceHiveMetastoreKerberosPrincipal=hive/_HOST@EXAMPLE.COM
sourceHive2KerberosPrincipal=hive/_HOST@EXAMPLE.COM

##### Target Cluster DR properties
targetCluster=backupCluster
targetMetastoreUri=thrift://localhost:9083
targetHiveServer2Uri=hive2://localhost:10000
## Please specify staging dir in the target without fully qualified domain name.
targetStagingPath=/apps/hive/tools/dr
targetNN=hdfs://localhost:8020
# Specify kerberos principal required to access target namenode and hive servers, optional on non-secure cluster.
targetNNKerberosPrincipal=nn/_HOST@EXAMPLE.COM
targetHiveMetastoreKerberosPrincipal=hive/_HOST@EXAMPLE.COM
targetHive2KerberosPrincipal=hive/_HOST@EXAMPLE.COM

# To ceil the max events processed each time job runs. Set it to max value depending on your bandwidth limit.
# Setting it to -1 will process all the events but can hog up the bandwidth. Use it judiciously!
maxEvents=-1
# Change it to specify the maximum number of mappers for replication
replicationMaxMaps=5
# Change it to specify the maximum number of mappers for DistCP
distcpMaxMaps=1
# Change it to specify the bandwidth in MB for each mapper in DistCP
distcpMapBandwidth=100
# Set this flag to true if TDE encryption is enabled on source and target
tdeEncryptionEnabled=false

##### Email Notification for Falcon instance completion
falcon.recipe.notification.type=email
falcon.recipe.notification.receivers=NA